{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hidden-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dirty-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/ESAA/21-1/costarica/train.csv')\n",
    "test = pd.read_csv('D:/ESAA/21-1/costarica/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "muslim-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-spouse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "passing-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dependency'] = np.sqrt(train['SQBdependency'])\n",
    "test['dependency'] = np.sqrt(test['SQBdependency'])\n",
    "\n",
    "# education=no -> 0\n",
    "train.loc[train['edjefa'] == \"no\", \"edjefa\"] = 0\n",
    "train.loc[train['edjefe'] == \"no\", \"edjefe\"] = 0\n",
    "\n",
    "test.loc[test['edjefa'] == \"no\", \"edjefa\"] = 0\n",
    "test.loc[test['edjefe'] == \"no\", \"edjefe\"] = 0\n",
    "\n",
    "# education=yes & household -> escolari\n",
    "train.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"edjefa\"] = train.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\n",
    "train.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"edjefe\"] = train.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "test.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"edjefa\"] = test.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\n",
    "test.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"edjefe\"] = test.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "# education=yes 지만 household 여부 모르면 -> 4\n",
    "train.loc[train['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "train.loc[train['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "test.loc[test['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "test.loc[test['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "# convert to int \n",
    "train['edjefe'] = train['edjefe'].astype(\"int\")\n",
    "train['edjefa'] = train['edjefa'].astype(\"int\")\n",
    "test['edjefe'] = test['edjefe'].astype(\"int\")\n",
    "test['edjefa'] = test['edjefa'].astype(\"int\")\n",
    "\n",
    "# create feature with max education of either head of household\n",
    "train['edjef'] = np.max(train[['edjefa','edjefe']], axis=1)\n",
    "test['edjef'] = np.max(test[['edjefa','edjefe']], axis=1)\n",
    "\n",
    "# fill some nas\n",
    "train['v2a1']=train['v2a1'].fillna(0)\n",
    "test['v2a1']=test['v2a1'].fillna(0)\n",
    "\n",
    "test['v18q1']=test['v18q1'].fillna(0)\n",
    "train['v18q1']=train['v18q1'].fillna(0)\n",
    "\n",
    "train['rez_esc']=train['rez_esc'].fillna(0)\n",
    "test['rez_esc']=test['rez_esc'].fillna(0)\n",
    "\n",
    "train.loc[train.meaneduc.isnull(), \"meaneduc\"] = 0\n",
    "train.loc[train.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n",
    "\n",
    "test.loc[test.meaneduc.isnull(), \"meaneduc\"] = 0\n",
    "test.loc[test.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n",
    "\n",
    "# fix some inconsistencies in the data - some rows indicate both that the household does and does not have a toilet, \n",
    "# if there is no water we'll assume they do not\n",
    "train.loc[(train.v14a ==  1) & (train.sanitario1 ==  1) & (train.abastaguano == 0), \"v14a\"] = 0\n",
    "train.loc[(train.v14a ==  1) & (train.sanitario1 ==  1) & (train.abastaguano == 0), \"sanitario1\"] = 0\n",
    "\n",
    "test.loc[(test.v14a ==  1) & (test.sanitario1 ==  1) & (test.abastaguano == 0), \"v14a\"] = 0\n",
    "test.loc[(test.v14a ==  1) & (test.sanitario1 ==  1) & (test.abastaguano == 0), \"sanitario1\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-qualification",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "scenic-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_data(df):\n",
    "        \n",
    "    yes_no_map = {'no': 0, 'yes': 1}\n",
    "    \n",
    "    df['dependency'] = df['dependency'].replace(yes_no_map).astype(np.float32)\n",
    "    \n",
    "    df['edjefe'] = df['edjefe'].replace(yes_no_map).astype(np.float32)\n",
    "    df['edjefa'] = df['edjefa'].replace(yes_no_map).astype(np.float32)\n",
    "    \n",
    "    df['idhogar'] = LabelEncoder().fit_transform(df['idhogar'])\n",
    "\n",
    "    \n",
    "def do_features(df):\n",
    "    feats_div = [('children_fraction', 'r4t1', 'r4t3'), \n",
    "                 ('working_man_fraction', 'r4h2', 'r4t3'),\n",
    "                 ('all_man_fraction', 'r4h3', 'r4t3'),\n",
    "                 ('human_density', 'tamviv', 'rooms'),\n",
    "                 ('human_bed_density', 'tamviv', 'bedrooms'),\n",
    "                 ('rent_per_person', 'v2a1', 'r4t3'),\n",
    "                 ('rent_per_room', 'v2a1', 'rooms'),\n",
    "                 ('mobile_density', 'qmobilephone', 'r4t3'),\n",
    "                 ('tablet_density', 'v18q1', 'r4t3'),\n",
    "                 ('mobile_adult_density', 'qmobilephone', 'r4t2'),\n",
    "                 ('tablet_adult_density', 'v18q1', 'r4t2'),\n",
    "                 #('', '', ''),\n",
    "                ]\n",
    "    \n",
    "    feats_sub = [('people_not_living', 'tamhog', 'tamviv'),\n",
    "                 ('people_weird_stat', 'tamhog', 'r4t3')]\n",
    "\n",
    "    for f_new, f1, f2 in feats_div:\n",
    "        df['fe_' + f_new] = (df[f1] / df[f2]).astype(np.float32)       \n",
    "    for f_new, f1, f2 in feats_sub:\n",
    "        df['fe_' + f_new] = (df[f1] - df[f2]).astype(np.float32)\n",
    "    \n",
    "    # aggregation rules over household\n",
    "    aggs_num = {'age': ['min', 'max', 'mean', 'count'],\n",
    "                'escolari': ['min', 'max', 'mean']\n",
    "               }\n",
    "    aggs_cat = {'dis': ['mean', 'sum']}\n",
    "    for s_ in ['estadocivil', 'parentesco', 'instlevel']:\n",
    "        for f_ in [f_ for f_ in df.columns if f_.startswith(s_)]:\n",
    "            aggs_cat[f_] = ['mean']\n",
    "    # aggregation over household\n",
    "    for name_, df_ in [('18', df.query('age >= 18'))]:\n",
    "        df_agg = df_.groupby('idhogar').agg({**aggs_num, **aggs_cat}).astype(np.float32)\n",
    "        df_agg.columns = pd.Index(['agg' + name_ + '_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "        df = df.join(df_agg, how='left', on='idhogar')\n",
    "        del df_agg\n",
    "    # do something advanced above...\n",
    "    \n",
    "    # Drop SQB variables, as they are just squres of other vars \n",
    "    df.drop([f_ for f_ in df.columns if f_.startswith('SQB') or f_ == 'agesq'], axis=1, inplace=True)\n",
    "    # Drop id's\n",
    "    df.drop(['Id'], axis=1, inplace=True)\n",
    "    # Drop repeated columns\n",
    "    df.drop(['hhsize', 'female', 'area2'], axis=1, inplace=True)\n",
    "    return df\n",
    "    \n",
    "def convert_OHE2LE(df):\n",
    "    tmp_df = df.copy(deep=True)\n",
    "    for s_ in ['pared', 'piso', 'techo', 'abastagua', 'sanitario', 'energcocinar', 'elimbasu', \n",
    "               'epared', 'etecho', 'eviv', 'estadocivil', 'parentesco', \n",
    "               'instlevel', 'lugar', 'tipovivi',\n",
    "               'manual_elec']:\n",
    "        if 'manual_' not in s_:\n",
    "            cols_s_ = [f_ for f_ in df.columns if f_.startswith(s_)]\n",
    "        elif 'elec' in s_:\n",
    "            cols_s_ = ['public', 'planpri', 'noelec', 'coopele']\n",
    "        sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "        #deal with those OHE, where there is a sum over columns == 0\n",
    "        if 0 in sum_ohe:\n",
    "            print('The OHE in {} is incomplete. A new column will be added before label encoding'\n",
    "                  .format(s_))\n",
    "            # dummy colmn name to be added\n",
    "            col_dummy = s_+'_dummy'\n",
    "            # add the column to the dataframe\n",
    "            tmp_df[col_dummy] = (tmp_df[cols_s_].sum(axis=1) == 0).astype(np.int8)\n",
    "            # add the name to the list of columns to be label-encoded\n",
    "            cols_s_.append(col_dummy)\n",
    "            # proof-check, that now the category is complete\n",
    "            sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "            if 0 in sum_ohe:\n",
    "                 print(\"The category completion did not work\")\n",
    "        tmp_cat = tmp_df[cols_s_].idxmax(axis=1)\n",
    "        tmp_df[s_ + '_LE'] = LabelEncoder().fit_transform(tmp_cat).astype(np.int16)\n",
    "        if 'parentesco1' in cols_s_:\n",
    "            cols_s_.remove('parentesco1')\n",
    "        tmp_df.drop(cols_s_, axis=1, inplace=True)\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "religious-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df_):\n",
    "    encode_data(df_)\n",
    "    return do_features(df_)\n",
    "\n",
    "train = process_df(train)\n",
    "test = process_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "expensive-nirvana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['v2a1', 'hacdor', 'rooms', 'hacapo', 'v14a', 'refrig', 'v18q', 'v18q1',\n",
      "       'r4h1', 'r4h2',\n",
      "       ...\n",
      "       'agg18_parentesco12_MEAN', 'agg18_instlevel1_MEAN',\n",
      "       'agg18_instlevel2_MEAN', 'agg18_instlevel3_MEAN',\n",
      "       'agg18_instlevel4_MEAN', 'agg18_instlevel5_MEAN',\n",
      "       'agg18_instlevel6_MEAN', 'agg18_instlevel7_MEAN',\n",
      "       'agg18_instlevel8_MEAN', 'agg18_instlevel9_MEAN'],\n",
      "      dtype='object', length=180)\n"
     ]
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "floral-going",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['v2a1', 'hacdor', 'rooms', 'hacapo', 'v14a', 'refrig', 'v18q', 'v18q1',\n",
       "       'r4h1', 'r4h2',\n",
       "       ...\n",
       "       'agg18_parentesco12_MEAN', 'agg18_instlevel1_MEAN',\n",
       "       'agg18_instlevel2_MEAN', 'agg18_instlevel3_MEAN',\n",
       "       'agg18_instlevel4_MEAN', 'agg18_instlevel5_MEAN',\n",
       "       'agg18_instlevel6_MEAN', 'agg18_instlevel7_MEAN',\n",
       "       'agg18_instlevel8_MEAN', 'agg18_instlevel9_MEAN'],\n",
       "      dtype='object', length=179)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-snake",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "specific-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_apply_func(train_, test_, func_):\n",
    "    test_['Target'] = 0\n",
    "    xx = pd.concat([train_, test_])\n",
    "\n",
    "    xx_func = func_(xx)\n",
    "    train_ = xx_func.iloc[:train_.shape[0], :]\n",
    "    test_  = xx_func.iloc[train_.shape[0]:, :].drop('Target', axis=1)\n",
    "\n",
    "    del xx, xx_func\n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "finished-civilian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OHE in techo is incomplete. A new column will be added before label encoding\n",
      "The OHE in instlevel is incomplete. A new column will be added before label encoding\n",
      "The OHE in manual_elec is incomplete. A new column will be added before label encoding\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_apply_func(train, test, convert_OHE2LE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-regular",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "instant-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_2_ohe = ['eviv_LE', 'etecho_LE', 'epared_LE', 'elimbasu_LE', \n",
    "              'energcocinar_LE', 'sanitario_LE', 'manual_elec_LE',\n",
    "              'pared_LE']\n",
    "cols_nums = ['age', 'meaneduc', 'dependency', \n",
    "             'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total',\n",
    "             'bedrooms', 'overcrowding']\n",
    "\n",
    "def convert_geo2aggs(df_):\n",
    "    tmp_df = pd.concat([df_[(['lugar_LE', 'idhogar']+cols_nums)],\n",
    "                        pd.get_dummies(df_[cols_2_ohe], \n",
    "                                       columns=cols_2_ohe)],axis=1)\n",
    "\n",
    "    geo_agg = tmp_df.groupby(['lugar_LE','idhogar']).mean().groupby('lugar_LE').mean().astype(np.float32)\n",
    "    geo_agg.columns = pd.Index(['geo_' + e for e in geo_agg.columns.tolist()])\n",
    "    \n",
    "    del tmp_df\n",
    "    return df_.join(geo_agg, how='left', on='lugar_LE')\n",
    "\n",
    "# add some aggregates by geography\n",
    "train, test = train_test_apply_func(train, test, convert_geo2aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "laughing-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['num_over_18'] = 0\n",
    "train['num_over_18'] = train[train.age >= 18].groupby('idhogar').transform(\"count\")\n",
    "train['num_over_18'] = train.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n",
    "train['num_over_18'] = train['num_over_18'].fillna(0)\n",
    "\n",
    "test['num_over_18'] = 0\n",
    "test['num_over_18'] = test[test.age >= 18].groupby('idhogar').transform(\"count\")\n",
    "test['num_over_18'] = test.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n",
    "test['num_over_18'] = test['num_over_18'].fillna(0)\n",
    "\n",
    "# add some extra features, these were taken from another kernel\n",
    "def extract_features(df):\n",
    "    df['bedrooms_to_rooms'] = df['bedrooms']/df['rooms']\n",
    "    df['rent_to_rooms'] = df['v2a1']/df['rooms']\n",
    "    df['tamhog_to_rooms'] = df['tamhog']/df['rooms'] # tamhog - size of the household\n",
    "    df['r4t3_to_tamhog'] = df['r4t3']/df['tamhog'] # r4t3 - Total persons in the household\n",
    "    df['r4t3_to_rooms'] = df['r4t3']/df['rooms'] # r4t3 - Total persons in the household\n",
    "    df['v2a1_to_r4t3'] = df['v2a1']/df['r4t3'] # rent to people in household\n",
    "    df['v2a1_to_r4t3'] = df['v2a1']/(df['r4t3'] - df['r4t1']) # rent to people under age 12\n",
    "    df['hhsize_to_rooms'] = df['hhsize']/df['rooms'] # rooms per person\n",
    "    df['rent_to_hhsize'] = df['v2a1']/df['hhsize'] # rent to household size\n",
    "    df['rent_to_over_18'] = df['v2a1']/df['num_over_18']\n",
    "    # some households have no one over 18, use the total rent for those\n",
    "    df.loc[df.num_over_18 == 0, \"rent_to_over_18\"] = df[df.num_over_18 == 0].v2a1\n",
    "    \n",
    "extract_features(train)    \n",
    "extract_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "relative-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "needless_cols = ['r4t3', 'tamhog', 'tamviv', 'hhsize', 'v18q', 'v14a', 'agesq',\n",
    "                 'mobilephone', 'female', ]\n",
    "\n",
    "instlevel_cols = [s for s in train.columns.tolist() if 'instlevel' in s]\n",
    "\n",
    "needless_cols.extend(instlevel_cols)\n",
    "\n",
    "train = train.drop(needless_cols, axis=1)\n",
    "test = test.drop(needless_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-backing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "manual-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train, y, sample_weight=None, households=None, test_percentage=0.20, seed=None):\n",
    "    # uncomment for extra randomness\n",
    "#     np.random.seed(seed=seed)\n",
    "    \n",
    "    train2 = train.copy()\n",
    "    \n",
    "    # pick some random households to use for the test data\n",
    "    cv_hhs = np.random.choice(households, size=int(len(households) * test_percentage), replace=False)\n",
    "    \n",
    "    # select households which are in the random selection\n",
    "    cv_idx = np.isin(households, cv_hhs)\n",
    "    X_test = train2[cv_idx]\n",
    "    y_test = y[cv_idx]\n",
    "\n",
    "    X_train = train2[~cv_idx]\n",
    "    y_train = y[~cv_idx]\n",
    "    \n",
    "    if sample_weight is not None:\n",
    "        y_train_weights = sample_weight[~cv_idx]\n",
    "        return X_train, y_train, X_test, y_test, y_train_weights\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ordered-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.query('parentesco1==1')\n",
    "# X = train.copy()\n",
    "\n",
    "# pull out and drop the target variable\n",
    "y = X['Target'] - 1\n",
    "X = X.drop(['Target'], axis=1)\n",
    "\n",
    "np.random.seed(seed=None)\n",
    "\n",
    "train2 = X.copy()\n",
    "\n",
    "train_hhs = train2.idhogar\n",
    "\n",
    "households = train2.idhogar.unique()\n",
    "cv_hhs = np.random.choice(households, size=int(len(households) * 0.15), replace=False)\n",
    "\n",
    "cv_idx = np.isin(train2.idhogar, cv_hhs)\n",
    "\n",
    "X_test = train2[cv_idx]\n",
    "y_test = y[cv_idx]\n",
    "\n",
    "X_train = train2[~cv_idx]\n",
    "y_train = y[~cv_idx]\n",
    "\n",
    "# train on entire dataset\n",
    "X_train = train2\n",
    "y_train = y\n",
    "\n",
    "train_households = X_train.idhogar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "unlikely-bread",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_weight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-bca2f906cbaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_train_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'class_weight' is not defined"
     ]
    }
   ],
   "source": [
    "y_train_weights = class_weight.compute_sample_weight('balanced', y_train, indices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-prince",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-happening",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seorim",
   "language": "python",
   "name": "seorim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
