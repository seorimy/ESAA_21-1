{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hidden-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dirty-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/ESAA/21-1/costarica/train.csv')\n",
    "test = pd.read_csv('D:/ESAA/21-1/costarica/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "standard-queue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>SQBescolari</th>\n",
       "      <th>SQBage</th>\n",
       "      <th>SQBhogar_total</th>\n",
       "      <th>SQBedjefe</th>\n",
       "      <th>SQBhogar_nin</th>\n",
       "      <th>SQBovercrowding</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_279628684</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>1849</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>1849</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_f29eb3ddd</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>4489</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0000</td>\n",
       "      <td>144.0000</td>\n",
       "      <td>4489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_68de51c94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>8464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>64.0000</td>\n",
       "      <td>121.0000</td>\n",
       "      <td>8464</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_d671db89c</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>289</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>121.0000</td>\n",
       "      <td>289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_d56d6f5f5</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>1369</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>121.0000</td>\n",
       "      <td>1369</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9552</th>\n",
       "      <td>ID_d45ae367d</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>2116</td>\n",
       "      <td>25</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>68.0625</td>\n",
       "      <td>2116</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9553</th>\n",
       "      <td>ID_c94744e07</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>68.0625</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9554</th>\n",
       "      <td>ID_85fc658f8</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>2500</td>\n",
       "      <td>25</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>68.0625</td>\n",
       "      <td>2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9555</th>\n",
       "      <td>ID_ced540c61</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>676</td>\n",
       "      <td>25</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>68.0625</td>\n",
       "      <td>676</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9556</th>\n",
       "      <td>ID_a38c64491</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>441</td>\n",
       "      <td>25</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>68.0625</td>\n",
       "      <td>441</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9557 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  \\\n",
       "0     ID_279628684  190000.0       0      3       0     1       1     0   \n",
       "1     ID_f29eb3ddd  135000.0       0      4       0     1       1     1   \n",
       "2     ID_68de51c94       NaN       0      8       0     1       1     0   \n",
       "3     ID_d671db89c  180000.0       0      5       0     1       1     1   \n",
       "4     ID_d56d6f5f5  180000.0       0      5       0     1       1     1   \n",
       "...            ...       ...     ...    ...     ...   ...     ...   ...   \n",
       "9552  ID_d45ae367d   80000.0       0      6       0     1       1     0   \n",
       "9553  ID_c94744e07   80000.0       0      6       0     1       1     0   \n",
       "9554  ID_85fc658f8   80000.0       0      6       0     1       1     0   \n",
       "9555  ID_ced540c61   80000.0       0      6       0     1       1     0   \n",
       "9556  ID_a38c64491   80000.0       0      6       0     1       1     0   \n",
       "\n",
       "      v18q1  r4h1  ...  SQBescolari  SQBage  SQBhogar_total  SQBedjefe  \\\n",
       "0       NaN     0  ...          100    1849               1        100   \n",
       "1       1.0     0  ...          144    4489               1        144   \n",
       "2       NaN     0  ...          121    8464               1          0   \n",
       "3       1.0     0  ...           81     289              16        121   \n",
       "4       1.0     0  ...          121    1369              16        121   \n",
       "...     ...   ...  ...          ...     ...             ...        ...   \n",
       "9552    NaN     0  ...           81    2116              25         81   \n",
       "9553    NaN     0  ...            0       4              25         81   \n",
       "9554    NaN     0  ...           25    2500              25         81   \n",
       "9555    NaN     0  ...          121     676              25         81   \n",
       "9556    NaN     0  ...           64     441              25         81   \n",
       "\n",
       "      SQBhogar_nin  SQBovercrowding  SQBdependency  SQBmeaned  agesq  Target  \n",
       "0                0         1.000000         0.0000   100.0000   1849       4  \n",
       "1                0         1.000000        64.0000   144.0000   4489       4  \n",
       "2                0         0.250000        64.0000   121.0000   8464       4  \n",
       "3                4         1.777778         1.0000   121.0000    289       4  \n",
       "4                4         1.777778         1.0000   121.0000   1369       4  \n",
       "...            ...              ...            ...        ...    ...     ...  \n",
       "9552             1         1.562500         0.0625    68.0625   2116       2  \n",
       "9553             1         1.562500         0.0625    68.0625      4       2  \n",
       "9554             1         1.562500         0.0625    68.0625   2500       2  \n",
       "9555             1         1.562500         0.0625    68.0625    676       2  \n",
       "9556             1         1.562500         0.0625    68.0625    441       2  \n",
       "\n",
       "[9557 rows x 143 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-present",
   "metadata": {},
   "source": [
    "- __Id__ - a unique identifier for each row.\n",
    "- __Target__ - the target is an ordinal variable indicating groups of income levels.\n",
    "    - 1 = extreme poverty\n",
    "    - 2 = moderate poverty\n",
    "    - 3 = vulnerable households\n",
    "    - 4 = non vulnerable households\n",
    "- __idhogar__ - this is a unique identifier for each household. This can be used to create household-wide features, etc. All rows in a given household will have a matching value for this identifier.\n",
    "- __parentesco1__ - indicates if this person is the head of the household."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-furniture",
   "metadata": {},
   "source": [
    "- __v2a1__, Monthly __rent payment__\n",
    "- hacdor, =1 Overcrowding by bedrooms\n",
    "- __rooms__,  __number of all rooms__ in the house\n",
    "- hacapo, =1 Overcrowding by rooms\n",
    "- v14a, =1 has bathroom in the household\n",
    "- refrig, =1 if the household has refrigerator\n",
    "- v18q, owns a tablet\n",
    "- v18q1, number of tablets household owns\n",
    "- r4h1, Males younger than 12 years of age\n",
    "- r4h2, Males 12 years of age and older\n",
    "- __r4h3__, __Total males__ in the household\n",
    "- r4m1, Females younger than 12 years of age\n",
    "- r4m2, Females 12 years of age and older\n",
    "- __r4m3__, __Total females__ in the household\n",
    "- r4t1, persons younger than 12 years of age\n",
    "- r4t2, persons 12 years of age and older\n",
    "- __r4t3__, __Total persons__ in the household\n",
    "- __tamhog__, __size__ of the household\n",
    "- __tamviv__, __number of persons__ living in the household\n",
    "- escolari, years of schooling\n",
    "- rez_esc, Years behind in school\n",
    "- hhsize, household size\n",
    "- paredblolad, =1 if predominant material on the outside wall is block or brick\n",
    "- paredzocalo, =1 if predominant material on the outside wall is socket (wood, zinc or absbesto\n",
    "- paredpreb, =1 if predominant material on the outside wall is prefabricated or cement\n",
    "- pareddes, =1 if predominant material on the outside wall is waste material\n",
    "- paredmad, =1 if predominant material on the outside wall is wood\n",
    "- paredzinc, =1 if predominant material on the outside wall is zink\n",
    "- paredfibras, =1 if predominant material on the outside wall is natural fibers\n",
    "- paredother, =1 if predominant material on the outside wall is other\n",
    "- pisomoscer, =1 if predominant material on the floor is mosaic,  ceramic,  terrazo\n",
    "- pisocemento, =1 if predominant material on the floor is cement\n",
    "- pisoother, =1 if predominant material on the floor is other\n",
    "- pisonatur, =1 if predominant material on the floor is  natural material\n",
    "- pisonotiene, =1 if no floor at the household\n",
    "- pisomadera, =1 if predominant material on the floor is wood\n",
    "- techozinc, =1 if predominant material on the roof is metal foil or zink\n",
    "- techoentrepiso, =1 if predominant material on the roof is fiber cement,  mezzanine \n",
    "- techocane, =1 if predominant material on the roof is natural fibers\n",
    "- techootro, =1 if predominant material on the roof is other\n",
    "- cielorazo, =1 if the house has ceiling\n",
    "- abastaguadentro, =1 if water provision inside the dwelling\n",
    "- abastaguafuera, =1 if water provision outside the dwelling\n",
    "- abastaguano, =1 if no water provision\n",
    "- public, \"=1 electricity from CNFL,  ICE,  ESPH/JASEC\"\n",
    "- planpri, =1 electricity from private plant\n",
    "- noelec, =1 no electricity in the dwelling\n",
    "- coopele, =1 electricity from cooperative\n",
    "- sanitario1, =1 no toilet in the dwelling\n",
    "- sanitario2, =1 toilet connected to sewer or cesspool\n",
    "- sanitario3, =1 toilet connected to  septic tank\n",
    "- sanitario5, =1 toilet connected to black hole or letrine\n",
    "- sanitario6, =1 toilet connected to other system\n",
    "- energcocinar1, =1 no main source of energy used for cooking (no kitchen)\n",
    "- energcocinar2, =1 main source of energy used for cooking electricity\n",
    "- energcocinar3, =1 main source of energy used for cooking gas\n",
    "- energcocinar4, =1 main source of energy used for cooking wood charcoal\n",
    "- elimbasu1, =1 if rubbish disposal mainly by tanker truck\n",
    "- elimbasu2, =1 if rubbish disposal mainly by botan hollow or buried\n",
    "- elimbasu3, =1 if rubbish disposal mainly by burning\n",
    "- elimbasu4, =1 if rubbish disposal mainly by throwing in an unoccupied space\n",
    "- elimbasu5, \"=1 if rubbish disposal mainly by throwing in river,  creek or sea\"\n",
    "- elimbasu6, =1 if rubbish disposal mainly other\n",
    "- epared1, =1 if walls are bad\n",
    "- epared2, =1 if walls are regular\n",
    "- epared3, =1 if walls are good\n",
    "- etecho1, =1 if roof are bad\n",
    "- etecho2, =1 if roof are regular\n",
    "- etecho3, =1 if roof are good\n",
    "- eviv1, =1 if floor are bad\n",
    "- eviv2, =1 if floor are regular\n",
    "- eviv3, =1 if floor are good\n",
    "- dis, =1 if disable person\n",
    "- male, =1 if male\n",
    "- female, =1 if female\n",
    "- estadocivil1, =1 if less than 10 years old\n",
    "- estadocivil2, =1 if free or coupled uunion\n",
    "- estadocivil3, =1 if married\n",
    "- estadocivil4, =1 if divorced\n",
    "- estadocivil5, =1 if separated\n",
    "- estadocivil6, =1 if widow/er\n",
    "- estadocivil7, =1 if single\n",
    "- parentesco1, =1 if household head\n",
    "- parentesco2, =1 if spouse/partner\n",
    "- parentesco3, =1 if son/doughter\n",
    "- parentesco4, =1 if stepson/doughter\n",
    "- parentesco5, =1 if son/doughter in law\n",
    "- parentesco6, =1 if grandson/doughter\n",
    "- parentesco7, =1 if mother/father\n",
    "- parentesco8, =1 if father/mother in law\n",
    "- parentesco9, =1 if brother/sister\n",
    "- parentesco10, =1 if brother/sister in law\n",
    "- parentesco11, =1 if other family member\n",
    "- parentesco12, =1 if other non family member\n",
    "- __idhogar__, __Household level identifier__\n",
    "- hogar_nin, Number of children 0 to 19 in household\n",
    "- hogar_adul, Number of adults in household\n",
    "- hogar_mayor, # of individuals 65+ in the household\n",
    "- hogar_total, # of total individuals in the household\n",
    "- dependency, Dependency rate, calculated = (number of members of the household younger than 19 or older than 64)/(number of member of household between 19 and 64)\n",
    "- __edjefe__, __years of education of male head__ of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n",
    "- __edjefa__, __years of education of female head__ of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n",
    "- meaneduc,average years of education for adults (18+)\n",
    "- instlevel1, =1 no level of education\n",
    "- instlevel2, =1 incomplete primary\n",
    "- instlevel3, =1 complete primary\n",
    "- instlevel4, =1 incomplete academic secondary level\n",
    "- instlevel5, =1 complete academic secondary level\n",
    "- instlevel6, =1 incomplete technical secondary level\n",
    "- instlevel7, =1 complete technical secondary level\n",
    "- instlevel8, =1 undergraduate and higher education\n",
    "- instlevel9, =1 postgraduate higher education\n",
    "- __bedrooms__, number of __bedrooms__\n",
    "- overcrowding, # persons per room\n",
    "- tipovivi1, =1 own and fully paid house\n",
    "- tipovivi2, =1 own,  paying in installments\n",
    "- tipovivi3, =1 rented\n",
    "- tipovivi4, =1 precarious\n",
    "- tipovivi5, \"=1 other(assigned,  borrowed)\"\n",
    "- computer, =1 if the household has notebook or desktop computer\n",
    "- television, =1 if the household has TV\n",
    "- mobilephone, =1 if mobile phone\n",
    "- __qmobilephone, # of mobile phones__\n",
    "- lugar1, =1 region Central\n",
    "- lugar2, =1 region Chorotega\n",
    "- lugar3, =1 region PacÃƒÂ­fico central\n",
    "- lugar4, =1 region Brunca\n",
    "- lugar5, =1 region Huetar AtlÃƒÂ¡ntica\n",
    "- lugar6, =1 region Huetar Norte\n",
    "- area1, =1 zona urbana\n",
    "- area2, =2 zona rural\n",
    "- age, Age in years\n",
    "- SQBescolari, escolari squared\n",
    "- SQBage, age squared\n",
    "- SQBhogar_total, hogar_total squared\n",
    "- SQBedjefe, edjefe squared\n",
    "- SQBhogar_nin, hogar_nin squared\n",
    "- SQBovercrowding, overcrowding squared\n",
    "- SQBdependency, dependency squared\n",
    "- SQBmeaned, square of the mean years of education of adults (>=18) in the household\n",
    "- agesq, Age squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "finnish-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "#from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import VotingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "radical-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_data(df):\n",
    "    df[\"idhogar\"]=LabelEncoder().fit_transform(df[\"idhogar\"])\n",
    "    \n",
    "def feature_importance(forest, X_train, display_results=True):\n",
    "    ranked_list=[]\n",
    "    zero_features=[]\n",
    "    importances=forest.feature_importances_\n",
    "    indicies=np.argsort(importances)[::-1]\n",
    "    \n",
    "    if display_results:\n",
    "        print(\"Feature ranking:\")\n",
    "        \n",
    "    for f in range(X_train.shape[1]):\n",
    "        if display_results:\n",
    "            print(\"%d. featyre %d (%f)\"%(f+1, indicies[f], importances[indicies[f]])\n",
    "                 +\"-\"+X_train.columns[indicies[f]])\n",
    "        ranked_list.append(X_train.columns[indicies[f]])\n",
    "        \n",
    "        if importances[indicies[f]]==0.0:\n",
    "            zero_features.append(X_train.columns[indicies[f]])\n",
    "    return ranked_list, zero_features\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "injured-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_features(df):\n",
    "    feats_div=[('children_fraction', 'r4t1', 'r4t3'),\n",
    "                ('working_man_fraction', 'r4h2', 'r4t3'),\n",
    "                ('all_man_fraction', 'r4h3', 'r4t3'),\n",
    "                ('human_density', 'tamviv', 'rooms'),\n",
    "                ('human_bed_density', 'tamviv', 'bedrooms'),\n",
    "                ('rent_per_person', 'v2a1', 'r4t3'),\n",
    "                ('rent_per_room', 'v2a1', 'rooms'),\n",
    "                ('mobile_density', 'qmobilephone', 'r4t3'),\n",
    "                ('tablet_density', 'v18q1', 'r4t3'),\n",
    "                ('mobile_adult_density', 'qmobilephone', 'r4t2'),\n",
    "                ('tablet_adult_density', 'v18q1', 'r4t2')\n",
    "               ]\n",
    "    feats_sub=[('people_not_living', 'tamhog', 'tamviv'),\n",
    "               ('people_weird_stat', 'tamhog', 'r4t3')\n",
    "              ]\n",
    "    for f_new, f1, f2 in feats_div:\n",
    "        df[\"fe_\"+f_new]=(df[f1]/df[f2]).astype(np.float32)\n",
    "    for f_new, f1, f2 in feats_sub:\n",
    "        df[\"fe_\"+f_new]=(df[f1]-df[f2]).astype(np.float32)\n",
    "    \n",
    "    aggs_num={\"age\":[\"min\",\"max\",\"mean\"],\n",
    "              \"escolari\":[\"min\",\"max\",\"mean\"]\n",
    "             }\n",
    "    aggs_cat={\"dis\":[\"mean\"]}\n",
    "    \n",
    "    for s_ in [\"estadocivil\",\"parentesco\",\"instlevel\"]:\n",
    "        for f_ in [f_ for f_ in df.columns if f_.startswith(s_)]:\n",
    "            aggs_cat[f_]=[\"mean\",\"count\"]\n",
    "        \n",
    "    for name_, df_ in [(\"18\",df.query(\"age>=18\"))]:\n",
    "        df_agg=df_.groupby(\"idhogar\").agg({**aggs_num,**aggs_cat}).astype(np.float32)\n",
    "        df_agg.columns=pd.Index([\"agg\"+name_+\"_\"+e[0]+\"_\"+e[1].upper() for e in df_agg.columns.tolist()])\n",
    "        df=df.join(df_agg, how=\"left\", on=\"idhogar\")\n",
    "        del df_agg\n",
    "        \n",
    "    df.drop([\"Id\"], axis=1, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "present-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_OHE2LE(df):\n",
    "    tmp_df=df.copy(deep=True)\n",
    "    for s_ in ['pared', 'piso', 'techo', 'abastagua', 'sanitario', 'energcocinar',\n",
    "               'elimbasu', 'epared', 'etecho', 'eviv', 'estadocivil', 'parentesco',\n",
    "               'instlevel', 'lugar', 'tipovivi', 'manual_elec']:\n",
    "        if \"manual_\" not in s_:\n",
    "            cols_s_=[f_ for f_ in df.columns if f_.startswith(s_)]\n",
    "        elif \"elec\" in s_:\n",
    "            cols_s_=[\"public\",\"planpri\",\"noelec\",\"coopele\"]\n",
    "        sum_ohe=tmp_df[cols_s_].sum(axis=1).unique()\n",
    "        if 0 in sum_ohe:\n",
    "            print(\"The OHE in {} is incomplete. A new column will be added before label encoding\".format(s_))\n",
    "            col_dummy=s_+\"_dummy\"\n",
    "            tmp_df[col_dummy]=(tmp_df[cols_s_].sum(axis=1)==0).astype(np.int8)\n",
    "            #0이면 True=1, 1이면 False=0\n",
    "            cols_s_.append(col_dummy)\n",
    "            sum_ohe=tmp_df[cols_s_].sum(axis=1).unique()\n",
    "            if 0 in sum_ohe:\n",
    "                print(\"The category completion did not work\")\n",
    "        tmp_cat=tmp_df[cols_s_].idxmax(axis=1)\n",
    "        tmp_df[s_+\"_LE\"]=LabelEncoder().fit_transform(tmp_cat).astype(np.int16)\n",
    "        if \"parentesco1\" in cols_s_:\n",
    "            cols_s_.remove(\"parentesco1\")\n",
    "        tmp_df.drop(cols_s_, axis=1, inplace=True)\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-relative",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "muslim-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "demonstrated-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df_):\n",
    "    encode_data(df_)\n",
    "    return do_features(df_)\n",
    "\n",
    "train=process_df(train)\n",
    "test=process_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-model",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "passing-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dependency'] = np.sqrt(train['SQBdependency'])\n",
    "test['dependency'] = np.sqrt(test['SQBdependency'])\n",
    "\n",
    "#edjefa=years of education of female head\n",
    "#edjefe=years of education of male head \n",
    "#escolari=years of schooling\n",
    "\n",
    "# education=no -> edjefa=0\n",
    "train.loc[train['edjefa'] == \"no\", \"edjefa\"] = 0\n",
    "train.loc[train['edjefe'] == \"no\", \"edjefe\"] = 0\n",
    "test.loc[test['edjefa'] == \"no\", \"edjefa\"] = 0\n",
    "test.loc[test['edjefe'] == \"no\", \"edjefe\"] = 0\n",
    "\n",
    "# education=yes & household head -> edjefa=escolari(공부한 기간)\n",
    "train.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"edjefa\"] = train.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\n",
    "train.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"edjefe\"] = train.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\n",
    "test.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"edjefa\"] = test.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\n",
    "test.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"edjefe\"] = test.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "# education=yes 지만 household head 여부 모르면 -> edjefa=4\n",
    "train.loc[train['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "train.loc[train['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "test.loc[test['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "test.loc[test['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "# convert to int \n",
    "train['edjefe'] = train['edjefe'].astype(\"int\")\n",
    "train['edjefa'] = train['edjefa'].astype(\"int\")\n",
    "test['edjefe'] = test['edjefe'].astype(\"int\")\n",
    "test['edjefa'] = test['edjefa'].astype(\"int\")\n",
    "\n",
    "# household head의 최대 education 기간으로 edjef 만듦\n",
    "train['edjef'] = np.max(train[['edjefa','edjefe']], axis=1)\n",
    "test['edjef'] = np.max(test[['edjefa','edjefe']], axis=1)\n",
    "\n",
    "# na 처리\n",
    "train['v2a1']=train['v2a1'].fillna(0)\n",
    "test['v2a1']=test['v2a1'].fillna(0)\n",
    "\n",
    "test['v18q1']=test['v18q1'].fillna(0)\n",
    "train['v18q1']=train['v18q1'].fillna(0)\n",
    "\n",
    "train['rez_esc']=train['rez_esc'].fillna(0)\n",
    "test['rez_esc']=test['rez_esc'].fillna(0)\n",
    "\n",
    "train.loc[train.meaneduc.isnull(), \"meaneduc\"] = 0\n",
    "train.loc[train.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n",
    "\n",
    "test.loc[test.meaneduc.isnull(), \"meaneduc\"] = 0\n",
    "test.loc[test.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n",
    "\n",
    "# 화장실이 있는데 없다고 되어있는 경우\n",
    "# v14a=1: bathroom 있음\n",
    "# sanitario1=1: toilet 없음\n",
    "# abastaguano=0: water 있음\n",
    "\n",
    "# bathroom은 있는데 toilet이 없는 경우엔 둘다 없는걸로\n",
    "train.loc[(train.v14a ==  1) & (train.sanitario1 ==  1) & (train.abastaguano == 0), \"v14a\"] = 0\n",
    "train.loc[(train.v14a ==  1) & (train.sanitario1 ==  1) & (train.abastaguano == 0), \"sanitario1\"] = 0\n",
    "\n",
    "test.loc[(test.v14a ==  1) & (test.sanitario1 ==  1) & (test.abastaguano == 0), \"v14a\"] = 0\n",
    "test.loc[(test.v14a ==  1) & (test.sanitario1 ==  1) & (test.abastaguano == 0), \"sanitario1\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "practical-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_apply_func(train_,test_,func_):\n",
    "    test_[\"Target\"]=0\n",
    "    xx=pd.concat([train_,test_])\n",
    "    xx_func=func_(xx)\n",
    "    \n",
    "    train_=xx_func.iloc[:train_.shape[0],:]\n",
    "    test_=xx_func.iloc[train_.shape[0]:,:].drop(\"Target\",axis=1)\n",
    "    del xx,xx_func\n",
    "    return train_,test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "first-measure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OHE in techo is incomplete. A new column will be added before label encoding\n",
      "The OHE in instlevel is incomplete. A new column will be added before label encoding\n",
      "The OHE in manual_elec is incomplete. A new column will be added before label encoding\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_apply_func(train, test, convert_OHE2LE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-copper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "instant-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_2_ohe = ['eviv_LE', 'etecho_LE', 'epared_LE', 'elimbasu_LE', \n",
    "              'energcocinar_LE', 'sanitario_LE', 'manual_elec_LE',\n",
    "              'pared_LE']\n",
    "cols_nums = ['age', 'meaneduc', 'dependency', \n",
    "             'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total',\n",
    "             'bedrooms', 'overcrowding']\n",
    "\n",
    "def convert_geo2aggs(df_):\n",
    "    tmp_df = pd.concat([df_[(['lugar_LE', 'idhogar']+cols_nums)],\n",
    "                        pd.get_dummies(df_[cols_2_ohe], columns=cols_2_ohe)],axis=1)\n",
    "\n",
    "    geo_agg = tmp_df.groupby(['lugar_LE','idhogar']).mean().groupby('lugar_LE').mean().astype(np.float32)\n",
    "    geo_agg.columns = pd.Index(['geo_' + e for e in geo_agg.columns.tolist()])\n",
    "    \n",
    "    del tmp_df\n",
    "    return df_.join(geo_agg, how='left', on='lugar_LE')\n",
    "\n",
    "train, test = train_test_apply_func(train, test, convert_geo2aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "laughing-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 집에 18살 이상인 사람의 수\n",
    "train['num_over_18'] = 0\n",
    "train['num_over_18'] = train[train.age >= 18].groupby('idhogar').transform(\"count\") \n",
    "#18살 넘는 행 중 idhogar별로 groupby한 후 행 개수(count(를 변수로 추가\n",
    "train['num_over_18'] = train.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n",
    "#idhogar별로 groupby한 후 18살 넘는 행의 나이 중 최대값(max)을 변수로 추가\n",
    "train['num_over_18'] = train['num_over_18'].fillna(0)\n",
    "#na는 0으로\n",
    "\n",
    "test['num_over_18'] = 0\n",
    "test['num_over_18'] = test[test.age >= 18].groupby('idhogar').transform(\"count\")\n",
    "test['num_over_18'] = test.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n",
    "test['num_over_18'] = test['num_over_18'].fillna(0)\n",
    "\n",
    "# add some extra features, these were taken from another kernel\n",
    "def extract_features(df):\n",
    "    df['bedrooms_to_rooms'] = df['bedrooms']/df['rooms']\n",
    "    df['rent_to_rooms'] = df['v2a1']/df['rooms']\n",
    "    df['tamhog_to_rooms'] = df['tamhog']/df['rooms'] # tamhog - size of the household\n",
    "    df['r4t3_to_tamhog'] = df['r4t3']/df['tamhog'] # r4t3 - Total persons in the household\n",
    "    df['r4t3_to_rooms'] = df['r4t3']/df['rooms'] # r4t3 - Total persons in the household\n",
    "    df['v2a1_to_r4t3'] = df['v2a1']/df['r4t3'] # rent to people in household\n",
    "    df['v2a1_to_r4t3'] = df['v2a1']/(df['r4t3'] - df['r4t1']) # rent to people under age 12\n",
    "    df['hhsize_to_rooms'] = df['hhsize']/df['rooms'] # rooms per person\n",
    "    df['rent_to_hhsize'] = df['v2a1']/df['hhsize'] # rent to household size\n",
    "    df['rent_to_over_18'] = df['v2a1']/df['num_over_18']\n",
    "    # some households have no one over 18, use the total rent for those\n",
    "    df.loc[df.num_over_18 == 0, \"rent_to_over_18\"] = df[df.num_over_18 == 0].v2a1\n",
    "    \n",
    "extract_features(train)    \n",
    "extract_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "relative-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "needless_cols = ['r4t3', 'tamhog', 'tamviv', 'hhsize', 'v18q', 'v14a', 'agesq',\n",
    "                 'mobilephone', 'female', ]\n",
    "\n",
    "instlevel_cols = [s for s in train.columns.tolist() if 'instlevel' in s]\n",
    "\n",
    "needless_cols.extend(instlevel_cols) #list의 원소를 빼서 attend\n",
    "\n",
    "train = train.drop(needless_cols, axis=1)\n",
    "test = test.drop(needless_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-liver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "manual-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train, y, sample_weight=None, households=None, test_percentage=0.20, seed=None):\n",
    "    train2 = train.copy()\n",
    "\n",
    "    cv_hhs = np.random.choice(households, size=int(len(households) * test_percentage), replace=False)\n",
    "    cv_idx = np.isin(households, cv_hhs)\n",
    "    \n",
    "    X_test = train2[cv_idx]\n",
    "    y_test = y[cv_idx]\n",
    "\n",
    "    X_train = train2[~cv_idx] #포함 안되는 인덱스\n",
    "    y_train = y[~cv_idx]\n",
    "    \n",
    "    if sample_weight is not None:\n",
    "        y_train_weights = sample_weight[~cv_idx]\n",
    "        return X_train, y_train, X_test, y_test, y_train_weights\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ordered-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.query('parentesco1==1') #household head인 경우\n",
    "\n",
    "y = X['Target'] - 1 #왜 굳이 빼는걸까,,?\n",
    "X = X.drop(['Target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "balanced-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=None)\n",
    "\n",
    "train2 = X.copy()\n",
    "\n",
    "train_hhs = train2.idhogar\n",
    "households = train2.idhogar.unique()\n",
    "\n",
    "cv_hhs = np.random.choice(households, size=int(len(households) * 0.15), replace=False)\n",
    "cv_idx = np.isin(train2.idhogar, cv_hhs)\n",
    "\n",
    "X_test = train2[cv_idx]\n",
    "y_test = y[cv_idx]\n",
    "\n",
    "X_train = train2[~cv_idx]\n",
    "y_train = y[~cv_idx]\n",
    "\n",
    "X_train = train2\n",
    "y_train = y\n",
    "\n",
    "train_households = X_train.idhogar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "unlikely-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_weights = class_weight.compute_sample_weight('balanced', y_train, indices=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-berkeley",
   "metadata": {},
   "source": [
    "sklearn.utils.class_weight.compute_class_weight(class_weight, classes, y)\n",
    ": Estimate class weights for unbalanced datasets.\n",
    "- class_weight: \"balanced\" or None\n",
    " - \"balanced\": class weight=n_sample/(n_class*np.bincount(y))\n",
    " - None: class weight=uniform\n",
    "- classes: array of classes in data\n",
    "- y: array of original class per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "drawn-prince",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38037359, 0.38037359, 0.38037359, ..., 0.38037359, 1.68156109,\n",
       "       1.68156109])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fantastic-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_drop_features = [\n",
    " 'agg18_estadocivil1_MEAN',\n",
    " 'agg18_estadocivil6_COUNT',\n",
    " 'agg18_estadocivil7_COUNT',\n",
    " 'agg18_parentesco10_COUNT',\n",
    " 'agg18_parentesco11_COUNT',\n",
    " 'agg18_parentesco12_COUNT',\n",
    " 'agg18_parentesco1_COUNT',\n",
    " 'agg18_parentesco2_COUNT',\n",
    " 'agg18_parentesco3_COUNT',\n",
    " 'agg18_parentesco4_COUNT',\n",
    " 'agg18_parentesco5_COUNT',\n",
    " 'agg18_parentesco6_COUNT',\n",
    " 'agg18_parentesco7_COUNT',\n",
    " 'agg18_parentesco8_COUNT',\n",
    " 'agg18_parentesco9_COUNT',\n",
    " 'geo_elimbasu_LE_4',\n",
    " 'geo_energcocinar_LE_1',\n",
    " 'geo_energcocinar_LE_2',\n",
    " 'geo_epared_LE_0',\n",
    " 'geo_hogar_mayor',\n",
    " 'geo_manual_elec_LE_2',\n",
    " 'geo_pared_LE_3',\n",
    " 'geo_pared_LE_4',\n",
    " 'geo_pared_LE_5',\n",
    " 'geo_pared_LE_6',\n",
    " 'num_over_18',\n",
    " 'parentesco_LE',\n",
    " 'rez_esc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "sonic-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_drop_cols = extra_drop_features + [\"idhogar\",  'parentesco1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "adjustable-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_parameters = {'max_depth':35, \n",
    "                  'eta':0.15, \n",
    "                  'silent':1, \n",
    "                  'objective':'multi:softmax', \n",
    "                  'min_child_weight': 2, \n",
    "                  'num_class': 4, \n",
    "                  'gamma': 2.5, \n",
    "                  'colsample_bylevel': 1, \n",
    "                  'subsample': 0.95, \n",
    "                  'colsample_bytree': 0.85, \n",
    "                  'reg_lambda': 0.35 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "first-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_macroF1_lgb(predictions, true):\n",
    "    pred_labels=predictions.argmax(axis=1)\n",
    "    true=true.get_label()\n",
    "    f1=f1_score(true,pred_labels,average=\"macro\")\n",
    "    return(\"macroF1\", 1-f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "sharp-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params={\"early_stopping_rounds\":500,\n",
    "            \"eval_metric\" : evaluate_macroF1_lgb, \n",
    "            \"eval_set\" : [(X_train,y_train), (X_test,y_test)],\n",
    "            'verbose': False\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "joint-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_power_0997(current_iter):\n",
    "    base_learning_rate = 0.1\n",
    "    min_learning_rate = 0.02\n",
    "    lr = base_learning_rate  * np.power(.995, current_iter)\n",
    "    return max(lr, min_learning_rate)\n",
    "\n",
    "fit_params['verbose'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "congressional-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "def _parallel_fit_estimator(estimator1, X, y, sample_weight=None, threshold=True, **fit_params):\n",
    "    estimator=clone(estimator1)\n",
    "    if sample_weight is not None:\n",
    "        X_train, y_train, X_test, y_test, y_train_weight=split_data(X,y,sample_weight,households=train_households)\n",
    "    else:\n",
    "        X_train, y_train, X_test, y_test=split_data(X,y,None,households=train_households)\n",
    "    \n",
    "    fit_params[\"eval_set\"]=[(X_test,y_test)]\n",
    "    \n",
    "    \n",
    "    if sample_weight is not None:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(X_train, y_train)\n",
    "        else:\n",
    "            _=estimator.fit(X_train, y_train, sample_weight=y_train_weight, **fit_params)\n",
    "    else:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(X_train, y_train)\n",
    "        else:\n",
    "            _=estimator.fit(X_train, y_train, **fit_params)\n",
    "\n",
    "    if not isinstance(estimator1, ExtraTreesClassifier) and not isinstance(estimator1, RandomForestClassifier) and not isinstance(estimator1, xgb.XGBClassifier):\n",
    "        best_cv_round=np.argmax(estimator.evals_result_[\"validation_0\"][\"mlogloss\"])\n",
    "        best_cv=np.max(estimator.evals_result_[\"train\"][\"macroF1\"][best_cv_round])\n",
    "    else:\n",
    "        best_train=f1_score(y_train, estimator.predict(X_train), average=\"macro\")\n",
    "        best_cv=f1_score(y_test,estimator.predict(X_test), average=\"macro\")\n",
    "        print(\"Train F1:\", best_train)\n",
    "        print(\"Test F1:\", best_cv)\n",
    "    \n",
    "    if threshold:\n",
    "        if ((best_cv>0.37) and (best_train>0.75)) or ((best_cv>0.44) and (best_train>0.65)):\n",
    "            return estimator\n",
    "        else:\n",
    "            print(\"Unacceptable\")\n",
    "            return _parallel_fit_estimator(estimator1, X, y, sample_weight=sample_weight, **fit_params)\n",
    "    else:\n",
    "        return estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "informational-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "celtic-omega",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingClassifierLGBM(VotingClassifier):\n",
    "    def fit(self, X, y, sample_weight=None, threshold=True, **fit_params):\n",
    "        if isinstance(y, np.ndarray) and len(y.shape) > 1 and y.shape[1] > 1:\n",
    "            raise NotImplementedError('Multilabel and multi-output classification is not supported.')\n",
    "        if self.voting not in ('soft', 'hard'):\n",
    "            raise ValueError(\"Voting must be 'soft' or 'hard'; got (voting=%r)\"% self.voting)\n",
    "        \n",
    "        if self.estimators is None or len(self.estimators) == 0:\n",
    "            raise AttributeError('Invalid `estimators` attribute, `estimators` should be a list of (string, estimator) tuples')\n",
    "            \n",
    "        if (self.weights is not None and len(self.weights) != len(self.estimators)):\n",
    "            raise ValueError('Number of classifiers and weights must be equal; got %d weights, %d estimators'% (len(self.weights), len(self.estimators)))\n",
    "        \n",
    "        names, clfs = zip(*self.estimators)   \n",
    "        self._validate_names(names)\n",
    "        n_isnone = np.sum([clf is None for _, clf in self.estimators])\n",
    "        \n",
    "        if n_isnone == len(self.estimators):\n",
    "            raise ValueError('All estimators are None. At least one is required to be a classifier!')\n",
    "            \n",
    "        self.le_ = LabelEncoder().fit(y)\n",
    "        self.classes_ = self.le_.classes_\n",
    "        self.estimators_ = []\n",
    "\n",
    "        transformed_y = self.le_.transform(y)\n",
    "\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(delayed(_parallel_fit_estimator) (clone(clf), X, transformed_y, sample_weight=sample_weight, threshold=threshold, **fit_params) for clf in clfs if clf is not None)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "roman-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs=[]\n",
    "\n",
    "for i in range(15):\n",
    "    clf=xgb.XGBClassifier(random_state=217+i, n_estimators=300, learning_rate=0.15, n_jobs=4, **opt_parameters)\n",
    "    clfs.append((\"XGB{}\".format(i), clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "opening-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc=VotingClassifierLGBM(clfs, voting=\"soft\")\n",
    "del(clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "stunning-partner",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.464646\tvalidation_0-macroF1:0.646101\n",
      "Multiple eval metrics have been passed: 'validation_0-macroF1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-macroF1 hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-merror:0.377104\tvalidation_0-macroF1:0.578445\n",
      "[100]\tvalidation_0-merror:0.367003\tvalidation_0-macroF1:0.570407\n",
      "[150]\tvalidation_0-merror:0.373737\tvalidation_0-macroF1:0.583402\n",
      "[200]\tvalidation_0-merror:0.37037\tvalidation_0-macroF1:0.583715\n",
      "[250]\tvalidation_0-merror:0.368687\tvalidation_0-macroF1:0.583333\n",
      "[299]\tvalidation_0-merror:0.368687\tvalidation_0-macroF1:0.583474\n",
      "Train F1: 0.9153725233385168\n",
      "Test F1: 0.4355385068644192\n",
      "[0]\tvalidation_0-merror:0.469697\tvalidation_0-macroF1:0.640044\n",
      "Multiple eval metrics have been passed: 'validation_0-macroF1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-macroF1 hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-merror:0.380471\tvalidation_0-macroF1:0.583417\n",
      "[100]\tvalidation_0-merror:0.385522\tvalidation_0-macroF1:0.599753\n",
      "[150]\tvalidation_0-merror:0.377104\tvalidation_0-macroF1:0.593972\n",
      "[200]\tvalidation_0-merror:0.377104\tvalidation_0-macroF1:0.597668\n",
      "[250]\tvalidation_0-merror:0.380471\tvalidation_0-macroF1:0.605199\n",
      "[299]\tvalidation_0-merror:0.373737\tvalidation_0-macroF1:0.594076\n",
      "Train F1: 0.8913538399552563\n",
      "Test F1: 0.42422233276003724\n",
      "[0]\tvalidation_0-merror:0.473064\tvalidation_0-macroF1:0.676192\n",
      "Multiple eval metrics have been passed: 'validation_0-macroF1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-macroF1 hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-merror:0.387205\tvalidation_0-macroF1:0.593712\n",
      "[100]\tvalidation_0-merror:0.387205\tvalidation_0-macroF1:0.595794\n",
      "[150]\tvalidation_0-merror:0.385522\tvalidation_0-macroF1:0.589911\n",
      "[200]\tvalidation_0-merror:0.383838\tvalidation_0-macroF1:0.589821\n",
      "[250]\tvalidation_0-merror:0.387205\tvalidation_0-macroF1:0.597476\n",
      "[299]\tvalidation_0-merror:0.388889\tvalidation_0-macroF1:0.596718\n",
      "Train F1: 0.8724441306732305\n",
      "Test F1: 0.42075548221923303\n",
      "[0]\tvalidation_0-merror:0.506734\tvalidation_0-macroF1:0.686421\n",
      "Multiple eval metrics have been passed: 'validation_0-macroF1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-macroF1 hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-merror:0.356902\tvalidation_0-macroF1:0.531409\n",
      "[100]\tvalidation_0-merror:0.360269\tvalidation_0-macroF1:0.541944\n",
      "[150]\tvalidation_0-merror:0.361953\tvalidation_0-macroF1:0.543682\n",
      "[200]\tvalidation_0-merror:0.360269\tvalidation_0-macroF1:0.537668\n",
      "[250]\tvalidation_0-merror:0.356902\tvalidation_0-macroF1:0.530024\n",
      "[299]\tvalidation_0-merror:0.355219\tvalidation_0-macroF1:0.539738\n",
      "Train F1: 0.9054438067880621\n",
      "Test F1: 0.47823529311636404\n",
      "[0]\tvalidation_0-merror:0.488215\tvalidation_0-macroF1:0.690363\n",
      "Multiple eval metrics have been passed: 'validation_0-macroF1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-macroF1 hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-merror:0.407407\tvalidation_0-macroF1:0.601575\n",
      "[100]\tvalidation_0-merror:0.390572\tvalidation_0-macroF1:0.591384\n",
      "[150]\tvalidation_0-merror:0.390572\tvalidation_0-macroF1:0.593051\n",
      "[200]\tvalidation_0-merror:0.395623\tvalidation_0-macroF1:0.601453\n",
      "[250]\tvalidation_0-merror:0.397306\tvalidation_0-macroF1:0.604831\n",
      "[299]\tvalidation_0-merror:0.397306\tvalidation_0-macroF1:0.609499\n",
      "Train F1: 0.9108878975200805\n",
      "Test F1: 0.4173477361936218\n",
      "[0]\tvalidation_0-merror:0.459596\tvalidation_0-macroF1:0.633155\n",
      "Multiple eval metrics have been passed: 'validation_0-macroF1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-macroF1 hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-merror:0.402357\tvalidation_0-macroF1:0.617957\n",
      "[100]\tvalidation_0-merror:0.395623\tvalidation_0-macroF1:0.614103\n",
      "[150]\tvalidation_0-merror:0.390572\tvalidation_0-macroF1:0.604858\n",
      "[200]\tvalidation_0-merror:0.393939\tvalidation_0-macroF1:0.612738\n",
      "[250]\tvalidation_0-merror:0.388889\tvalidation_0-macroF1:0.609966\n",
      "[299]\tvalidation_0-merror:0.388889\tvalidation_0-macroF1:0.610004\n",
      "Train F1: 0.8893336491231894\n",
      "Test F1: 0.4051414966703659\n",
      "[0]\tvalidation_0-merror:0.464646\tvalidation_0-macroF1:0.667382\n",
      "Multiple eval metrics have been passed: 'validation_0-macroF1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-macroF1 hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-merror:0.383838\tvalidation_0-macroF1:0.601972\n",
      "[100]\tvalidation_0-merror:0.378788\tvalidation_0-macroF1:0.605368\n",
      "[150]\tvalidation_0-merror:0.378788\tvalidation_0-macroF1:0.613276\n",
      "[200]\tvalidation_0-merror:0.387205\tvalidation_0-macroF1:0.620321\n",
      "[250]\tvalidation_0-merror:0.380471\tvalidation_0-macroF1:0.61699\n",
      "[299]\tvalidation_0-merror:0.377104\tvalidation_0-macroF1:0.614077\n",
      "Train F1: 0.8972810131834246\n",
      "Test F1: 0.40066108970156944\n",
      "[0]\tvalidation_0-merror:0.442761\tvalidation_0-macroF1:0.627544\n",
      "Multiple eval metrics have been passed: 'validation_0-macroF1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-macroF1 hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-merror:0.380471\tvalidation_0-macroF1:0.604169\n",
      "[100]\tvalidation_0-merror:0.372054\tvalidation_0-macroF1:0.601541\n",
      "[150]\tvalidation_0-merror:0.372054\tvalidation_0-macroF1:0.604035\n",
      "[200]\tvalidation_0-merror:0.37037\tvalidation_0-macroF1:0.606346\n",
      "[250]\tvalidation_0-merror:0.373737\tvalidation_0-macroF1:0.612084\n",
      "[299]\tvalidation_0-merror:0.372054\tvalidation_0-macroF1:0.611192\n",
      "Train F1: 0.9110203375242469\n",
      "Test F1: 0.4069266211820104\n",
      "[0]\tvalidation_0-merror:0.405724\tvalidation_0-macroF1:0.569948\n",
      "Multiple eval metrics have been passed: 'validation_0-macroF1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-macroF1 hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-merror:0.367003\tvalidation_0-macroF1:0.546907\n",
      "[100]\tvalidation_0-merror:0.36532\tvalidation_0-macroF1:0.55562\n",
      "[150]\tvalidation_0-merror:0.360269\tvalidation_0-macroF1:0.55303\n",
      "[200]\tvalidation_0-merror:0.350168\tvalidation_0-macroF1:0.545353\n",
      "[250]\tvalidation_0-merror:0.351852\tvalidation_0-macroF1:0.546489\n",
      "[299]\tvalidation_0-merror:0.351852\tvalidation_0-macroF1:0.547837\n",
      "Train F1: 0.9023161714314298\n",
      "Test F1: 0.4669456786718976\n",
      "[0]\tvalidation_0-merror:0.442761\tvalidation_0-macroF1:0.656075\n",
      "Multiple eval metrics have been passed: 'validation_0-macroF1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-macroF1 hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-merror:0.372054\tvalidation_0-macroF1:0.60366\n",
      "[100]\tvalidation_0-merror:0.363636\tvalidation_0-macroF1:0.596851\n",
      "[150]\tvalidation_0-merror:0.360269\tvalidation_0-macroF1:0.594956\n",
      "[200]\tvalidation_0-merror:0.355219\tvalidation_0-macroF1:0.59503\n",
      "[250]\tvalidation_0-merror:0.358586\tvalidation_0-macroF1:0.601222\n",
      "[299]\tvalidation_0-merror:0.356902\tvalidation_0-macroF1:0.60041\n",
      "Train F1: 0.891328566030215\n",
      "Test F1: 0.4133092608446235\n",
      "[0]\tvalidation_0-merror:0.442761\tvalidation_0-macroF1:0.635594\n",
      "Multiple eval metrics have been passed: 'validation_0-macroF1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-macroF1 hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-merror:0.377104\tvalidation_0-macroF1:0.598722\n",
      "[100]\tvalidation_0-merror:0.37037\tvalidation_0-macroF1:0.586422\n",
      "[150]\tvalidation_0-merror:0.363636\tvalidation_0-macroF1:0.572078\n",
      "[200]\tvalidation_0-merror:0.367003\tvalidation_0-macroF1:0.581793\n",
      "[250]\tvalidation_0-merror:0.363636\tvalidation_0-macroF1:0.572344\n",
      "[299]\tvalidation_0-merror:0.367003\tvalidation_0-macroF1:0.580221\n",
      "Train F1: 0.9200869829778409\n",
      "Test F1: 0.42932198053495463\n",
      "[0]\tvalidation_0-merror:0.447811\tvalidation_0-macroF1:0.643927\n",
      "Multiple eval metrics have been passed: 'validation_0-macroF1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-macroF1 hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-merror:0.380471\tvalidation_0-macroF1:0.591184\n",
      "[100]\tvalidation_0-merror:0.380471\tvalidation_0-macroF1:0.604466\n",
      "[150]\tvalidation_0-merror:0.383838\tvalidation_0-macroF1:0.613042\n",
      "[200]\tvalidation_0-merror:0.378788\tvalidation_0-macroF1:0.611924\n",
      "[250]\tvalidation_0-merror:0.382155\tvalidation_0-macroF1:0.609384\n",
      "[299]\tvalidation_0-merror:0.383838\tvalidation_0-macroF1:0.618041\n",
      "Train F1: 0.9006803320768149\n",
      "Test F1: 0.4254007528480266\n",
      "[0]\tvalidation_0-merror:0.442761\tvalidation_0-macroF1:0.615498\n",
      "Multiple eval metrics have been passed: 'validation_0-macroF1' will be used for early stopping.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until validation_0-macroF1 hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-merror:0.373737\tvalidation_0-macroF1:0.563908\n",
      "[100]\tvalidation_0-merror:0.37037\tvalidation_0-macroF1:0.561588\n",
      "[150]\tvalidation_0-merror:0.372054\tvalidation_0-macroF1:0.56399\n",
      "[200]\tvalidation_0-merror:0.368687\tvalidation_0-macroF1:0.564721\n",
      "[250]\tvalidation_0-merror:0.372054\tvalidation_0-macroF1:0.569799\n",
      "[299]\tvalidation_0-merror:0.372054\tvalidation_0-macroF1:0.565604\n",
      "Train F1: 0.868783685054759\n",
      "Test F1: 0.45728526150302823\n",
      "[0]\tvalidation_0-merror:0.442761\tvalidation_0-macroF1:0.599582\n",
      "Multiple eval metrics have been passed: 'validation_0-macroF1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-macroF1 hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-merror:0.39899\tvalidation_0-macroF1:0.590061\n",
      "[100]\tvalidation_0-merror:0.40404\tvalidation_0-macroF1:0.60687\n",
      "[150]\tvalidation_0-merror:0.400673\tvalidation_0-macroF1:0.600754\n",
      "[200]\tvalidation_0-merror:0.392256\tvalidation_0-macroF1:0.597934\n",
      "[250]\tvalidation_0-merror:0.395623\tvalidation_0-macroF1:0.604446\n",
      "[299]\tvalidation_0-merror:0.393939\tvalidation_0-macroF1:0.601292\n",
      "Train F1: 0.8967214529450815\n",
      "Test F1: 0.4262237902576739\n",
      "[0]\tvalidation_0-merror:0.441077\tvalidation_0-macroF1:0.635276\n",
      "Multiple eval metrics have been passed: 'validation_0-macroF1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-macroF1 hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-merror:0.348485\tvalidation_0-macroF1:0.564666\n",
      "[100]\tvalidation_0-merror:0.350168\tvalidation_0-macroF1:0.565395\n",
      "[150]\tvalidation_0-merror:0.351852\tvalidation_0-macroF1:0.569924\n",
      "[200]\tvalidation_0-merror:0.348485\tvalidation_0-macroF1:0.566517\n",
      "[250]\tvalidation_0-merror:0.348485\tvalidation_0-macroF1:0.571177\n",
      "[299]\tvalidation_0-merror:0.348485\tvalidation_0-macroF1:0.566762\n",
      "Train F1: 0.8935956630026125\n",
      "Test F1: 0.4472704708236759\n"
     ]
    }
   ],
   "source": [
    "_=vc.fit(X_train.drop(xgb_drop_cols, axis=1), y_train, sample_weight=y_train_weights,\n",
    "        threshold=False, **fit_params)\n",
    "clf_final=vc.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "metric-musical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score of a single LGBM Classifier: 0.7979\n",
      "Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: 0.8487\n",
      "Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: 0.8591\n"
     ]
    }
   ],
   "source": [
    "global_score = f1_score(y_test, clf_final.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "vc.voting = 'soft'\n",
    "global_score_soft = f1_score(y_test, vc.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "vc.voting = 'hard'\n",
    "global_score_hard = f1_score(y_test, vc.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "print('Validation score of a single LGBM Classifier: {:.4f}'.format(global_score))\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_score_soft))\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_score_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "norman-gilbert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agg18_estadocivil4_COUNT',\n",
       " 'agg18_estadocivil5_COUNT',\n",
       " 'geo_energcocinar_LE_0',\n",
       " 'geo_epared_LE_2',\n",
       " 'geo_manual_elec_LE_3'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useless_features = []\n",
    "drop_features = set()\n",
    "counter = 0\n",
    "for est in vc.estimators_:\n",
    "    ranked_features, unused_features = feature_importance(est, X_train.drop(xgb_drop_cols, axis=1), display_results=False)\n",
    "    useless_features.append(unused_features)\n",
    "    if counter == 0:\n",
    "        drop_features = set(unused_features)\n",
    "    else:\n",
    "        drop_features = drop_features.intersection(set(unused_features))\n",
    "    counter += 1\n",
    "    \n",
    "drop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "extended-guitar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. featyre 59 (0.020874)-agg18_escolari_MAX\n",
      "2. featyre 42 (0.019113)-fe_children_fraction\n",
      "3. featyre 37 (0.017560)-SQBedjefe\n",
      "4. featyre 126 (0.016810)-geo_sanitario_LE_3\n",
      "5. featyre 74 (0.015333)-agg18_parentesco2_MEAN\n",
      "6. featyre 46 (0.014168)-fe_human_bed_density\n",
      "7. featyre 22 (0.013392)-dependency\n",
      "8. featyre 60 (0.013138)-agg18_escolari_MEAN\n",
      "9. featyre 40 (0.012836)-SQBdependency\n",
      "10. featyre 135 (0.012545)-geo_pared_LE_7\n",
      "11. featyre 112 (0.012330)-geo_etecho_LE_1\n",
      "12. featyre 107 (0.011216)-geo_overcrowding\n",
      "13. featyre 124 (0.010565)-geo_sanitario_LE_1\n",
      "14. featyre 116 (0.010347)-geo_elimbasu_LE_0\n",
      "15. featyre 19 (0.010287)-hogar_adul\n",
      "16. featyre 34 (0.010142)-SQBescolari\n",
      "17. featyre 105 (0.009962)-geo_hogar_total\n",
      "18. featyre 23 (0.009942)-edjefe\n",
      "19. featyre 94 (0.009886)-etecho_LE\n",
      "20. featyre 17 (0.009594)-male\n",
      "21. featyre 39 (0.009528)-SQBovercrowding\n",
      "22. featyre 41 (0.009366)-SQBmeaned\n",
      "23. featyre 44 (0.009305)-fe_all_man_fraction\n",
      "24. featyre 96 (0.009216)-estadocivil_LE\n",
      "25. featyre 6 (0.009131)-r4h1\n",
      "26. featyre 97 (0.009013)-lugar_LE\n",
      "27. featyre 65 (0.008972)-agg18_estadocivil3_MEAN\n",
      "28. featyre 15 (0.008932)-cielorazo\n",
      "29. featyre 16 (0.008922)-dis\n",
      "30. featyre 120 (0.008912)-geo_elimbasu_LE_5\n",
      "31. featyre 93 (0.008863)-epared_LE\n",
      "32. featyre 106 (0.008822)-geo_bedrooms\n",
      "33. featyre 104 (0.008821)-geo_hogar_adul\n",
      "34. featyre 95 (0.008810)-eviv_LE\n",
      "35. featyre 98 (0.008801)-tipovivi_LE\n",
      "36. featyre 55 (0.008797)-agg18_age_MIN\n",
      "37. featyre 12 (0.008775)-r4t1\n",
      "38. featyre 92 (0.008711)-elimbasu_LE\n",
      "39. featyre 131 (0.008691)-geo_manual_elec_LE_4\n",
      "40. featyre 49 (0.008591)-fe_mobile_density\n",
      "41. featyre 35 (0.008552)-SQBage\n",
      "42. featyre 111 (0.008547)-geo_etecho_LE_0\n",
      "43. featyre 27 (0.008483)-overcrowding\n",
      "44. featyre 125 (0.008438)-geo_sanitario_LE_2\n",
      "45. featyre 14 (0.008432)-escolari\n",
      "46. featyre 5 (0.008364)-v18q1\n",
      "47. featyre 33 (0.008358)-age\n",
      "48. featyre 13 (0.008337)-r4t2\n",
      "49. featyre 87 (0.008315)-piso_LE\n",
      "50. featyre 86 (0.008305)-pared_LE\n",
      "51. featyre 117 (0.008305)-geo_elimbasu_LE_1\n",
      "52. featyre 25 (0.008275)-meaneduc\n",
      "53. featyre 123 (0.008270)-geo_sanitario_LE_0\n",
      "54. featyre 51 (0.008260)-fe_mobile_adult_density\n",
      "55. featyre 69 (0.008140)-agg18_estadocivil5_MEAN\n",
      "56. featyre 71 (0.008139)-agg18_estadocivil6_MEAN\n",
      "57. featyre 72 (0.008112)-agg18_estadocivil7_MEAN\n",
      "58. featyre 45 (0.008103)-fe_human_density\n",
      "59. featyre 30 (0.008054)-qmobilephone\n",
      "60. featyre 58 (0.008048)-agg18_escolari_MIN\n",
      "61. featyre 43 (0.008048)-fe_working_man_fraction\n",
      "62. featyre 102 (0.007966)-geo_dependency\n",
      "63. featyre 0 (0.007906)-v2a1\n",
      "64. featyre 128 (0.007870)-geo_manual_elec_LE_0\n",
      "65. featyre 10 (0.007865)-r4m2\n",
      "66. featyre 32 (0.007738)-area2\n",
      "67. featyre 7 (0.007579)-r4h2\n",
      "68. featyre 21 (0.007507)-hogar_total\n",
      "69. featyre 109 (0.007466)-geo_eviv_LE_1\n",
      "70. featyre 47 (0.007323)-fe_rent_per_person\n",
      "71. featyre 142 (0.007268)-hhsize_to_rooms\n",
      "72. featyre 63 (0.007225)-agg18_estadocivil2_MEAN\n",
      "73. featyre 136 (0.007217)-bedrooms_to_rooms\n",
      "74. featyre 1 (0.007192)-hacdor\n",
      "75. featyre 138 (0.007158)-tamhog_to_rooms\n",
      "76. featyre 50 (0.007148)-fe_tablet_density\n",
      "77. featyre 2 (0.007079)-rooms\n",
      "78. featyre 29 (0.007009)-television\n",
      "79. featyre 91 (0.007006)-energcocinar_LE\n",
      "80. featyre 99 (0.007003)-manual_elec_LE\n",
      "81. featyre 57 (0.006932)-agg18_age_MEAN\n",
      "82. featyre 62 (0.006899)-agg18_estadocivil1_COUNT\n",
      "83. featyre 90 (0.006889)-sanitario_LE\n",
      "84. featyre 100 (0.006777)-geo_age\n",
      "85. featyre 31 (0.006771)-area1\n",
      "86. featyre 61 (0.006766)-agg18_dis_MEAN\n",
      "87. featyre 24 (0.006738)-edjefa\n",
      "88. featyre 8 (0.006734)-r4h3\n",
      "89. featyre 52 (0.006694)-fe_tablet_adult_density\n",
      "90. featyre 143 (0.006689)-rent_to_hhsize\n",
      "91. featyre 11 (0.006668)-r4m3\n",
      "92. featyre 122 (0.006643)-geo_energcocinar_LE_3\n",
      "93. featyre 48 (0.006560)-fe_rent_per_room\n",
      "94. featyre 64 (0.006504)-agg18_estadocivil2_COUNT\n",
      "95. featyre 56 (0.006441)-agg18_age_MAX\n",
      "96. featyre 20 (0.006432)-hogar_mayor\n",
      "97. featyre 26 (0.006391)-bedrooms\n",
      "98. featyre 9 (0.006350)-r4m1\n",
      "99. featyre 75 (0.006242)-agg18_parentesco3_MEAN\n",
      "100. featyre 4 (0.006161)-refrig\n",
      "101. featyre 18 (0.005876)-hogar_nin\n",
      "102. featyre 101 (0.005755)-geo_meaneduc\n",
      "103. featyre 38 (0.005725)-SQBhogar_nin\n",
      "104. featyre 103 (0.005689)-geo_hogar_nin\n",
      "105. featyre 28 (0.005391)-computer\n",
      "106. featyre 140 (0.005380)-r4t3_to_rooms\n",
      "107. featyre 88 (0.005258)-techo_LE\n",
      "108. featyre 144 (0.005221)-rent_to_over_18\n",
      "109. featyre 67 (0.005210)-agg18_estadocivil4_MEAN\n",
      "110. featyre 110 (0.005132)-geo_eviv_LE_2\n",
      "111. featyre 129 (0.005069)-geo_manual_elec_LE_1\n",
      "112. featyre 53 (0.005035)-fe_people_not_living\n",
      "113. featyre 79 (0.004939)-agg18_parentesco7_MEAN\n",
      "114. featyre 77 (0.004880)-agg18_parentesco5_MEAN\n",
      "115. featyre 137 (0.004457)-rent_to_rooms\n",
      "116. featyre 114 (0.004299)-geo_epared_LE_1\n",
      "117. featyre 81 (0.004282)-agg18_parentesco9_MEAN\n",
      "118. featyre 141 (0.004248)-v2a1_to_r4t3\n",
      "119. featyre 83 (0.004106)-agg18_parentesco11_MEAN\n",
      "120. featyre 133 (0.003824)-geo_pared_LE_1\n",
      "121. featyre 3 (0.003191)-hacapo\n",
      "122. featyre 78 (0.002986)-agg18_parentesco6_MEAN\n",
      "123. featyre 84 (0.002735)-agg18_parentesco12_MEAN\n",
      "124. featyre 89 (0.002506)-abastagua_LE\n",
      "125. featyre 139 (0.001633)-r4t3_to_tamhog\n",
      "126. featyre 76 (0.001460)-agg18_parentesco4_MEAN\n",
      "127. featyre 80 (0.000000)-agg18_parentesco8_MEAN\n",
      "128. featyre 132 (0.000000)-geo_pared_LE_0\n",
      "129. featyre 119 (0.000000)-geo_elimbasu_LE_3\n",
      "130. featyre 36 (0.000000)-SQBhogar_total\n",
      "131. featyre 82 (0.000000)-agg18_parentesco10_MEAN\n",
      "132. featyre 73 (0.000000)-agg18_parentesco1_MEAN\n",
      "133. featyre 118 (0.000000)-geo_elimbasu_LE_2\n",
      "134. featyre 130 (0.000000)-geo_manual_elec_LE_3\n",
      "135. featyre 70 (0.000000)-agg18_estadocivil5_COUNT\n",
      "136. featyre 68 (0.000000)-agg18_estadocivil4_COUNT\n",
      "137. featyre 115 (0.000000)-geo_epared_LE_2\n",
      "138. featyre 66 (0.000000)-agg18_estadocivil3_COUNT\n",
      "139. featyre 85 (0.000000)-edjef\n",
      "140. featyre 121 (0.000000)-geo_energcocinar_LE_0\n",
      "141. featyre 54 (0.000000)-fe_people_weird_stat\n",
      "142. featyre 108 (0.000000)-geo_eviv_LE_0\n",
      "143. featyre 134 (0.000000)-geo_pared_LE_2\n",
      "144. featyre 113 (0.000000)-geo_etecho_LE_2\n",
      "145. featyre 127 (0.000000)-geo_sanitario_LE_4\n"
     ]
    }
   ],
   "source": [
    "ranked_features = feature_importance(clf_final, X_train.drop(xgb_drop_cols, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-webster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "described-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_drop_cols = ['agg18_age_MAX', 'agg18_age_MEAN', 'agg18_age_MIN', 'agg18_dis_MEAN',\n",
    "       'agg18_escolari_MAX', 'agg18_escolari_MEAN', 'agg18_escolari_MIN',\n",
    "       'agg18_estadocivil1_COUNT', 'agg18_estadocivil1_MEAN',\n",
    "       'agg18_estadocivil2_COUNT', 'agg18_estadocivil2_MEAN',\n",
    "       'agg18_estadocivil3_COUNT', 'agg18_estadocivil3_MEAN',\n",
    "       'agg18_estadocivil4_COUNT', 'agg18_estadocivil4_MEAN',\n",
    "       'agg18_estadocivil5_COUNT', 'agg18_estadocivil5_MEAN',\n",
    "       'agg18_estadocivil6_COUNT', 'agg18_estadocivil6_MEAN',\n",
    "       'agg18_estadocivil7_COUNT', 'agg18_estadocivil7_MEAN',\n",
    "       'agg18_parentesco10_COUNT', 'agg18_parentesco10_MEAN',\n",
    "       'agg18_parentesco11_COUNT', 'agg18_parentesco11_MEAN',\n",
    "       'agg18_parentesco12_COUNT', 'agg18_parentesco12_MEAN',\n",
    "       'agg18_parentesco1_COUNT', 'agg18_parentesco1_MEAN',\n",
    "       'agg18_parentesco2_COUNT', 'agg18_parentesco2_MEAN',\n",
    "       'agg18_parentesco3_COUNT', 'agg18_parentesco3_MEAN',\n",
    "       'agg18_parentesco4_COUNT', 'agg18_parentesco4_MEAN',\n",
    "       'agg18_parentesco5_COUNT', 'agg18_parentesco5_MEAN',\n",
    "       'agg18_parentesco6_COUNT', 'agg18_parentesco6_MEAN',\n",
    "       'agg18_parentesco7_COUNT', 'agg18_parentesco7_MEAN',\n",
    "       'agg18_parentesco8_COUNT', 'agg18_parentesco8_MEAN',\n",
    "       'agg18_parentesco9_COUNT', 'agg18_parentesco9_MEAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fossil-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_drop_cols.extend([\"idhogar\", \"parentesco1\", 'fe_rent_per_person', 'fe_rent_per_room',\n",
    "       'fe_tablet_adult_density', 'fe_tablet_density'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "quarterly-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "ets = []    \n",
    "for i in range(10):\n",
    "    rf = RandomForestClassifier(max_depth=None, random_state=217+i, n_jobs=4, n_estimators=700, min_impurity_decrease=1e-3, min_samples_leaf=2, verbose=0, class_weight=\"balanced\")\n",
    "    ets.append(('rf{}'.format(i), rf))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "casual-treasure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.8970955314751967\n",
      "Test F1: 0.4339837350335132\n",
      "Train F1: 0.8978154737944584\n",
      "Test F1: 0.40102587275854407\n",
      "Train F1: 0.8984260514089941\n",
      "Test F1: 0.4178603966114821\n",
      "Train F1: 0.8989646974584208\n",
      "Test F1: 0.4474071002684059\n",
      "Train F1: 0.8946277247021607\n",
      "Test F1: 0.4040623090134163\n",
      "Train F1: 0.8942347190248382\n",
      "Test F1: 0.4420524924852226\n",
      "Train F1: 0.883377868986868\n",
      "Test F1: 0.38759359143567657\n",
      "Train F1: 0.8830889573677272\n",
      "Test F1: 0.3968373439696289\n",
      "Train F1: 0.8889972541497917\n",
      "Test F1: 0.4310054243471582\n",
      "Train F1: 0.8857021263049742\n",
      "Test F1: 0.4316117388522157\n"
     ]
    }
   ],
   "source": [
    "vc2 = VotingClassifierLGBM(ets, voting='soft')    \n",
    "_ = vc2.fit(X_train.drop(et_drop_cols, axis=1), y_train, threshold=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "assisted-french",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: 0.8389\n",
      "Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: 0.8483\n"
     ]
    }
   ],
   "source": [
    "vc2.voting = 'soft'\n",
    "global_rf_score_soft = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "vc2.voting = 'hard'\n",
    "global_rf_score_hard = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_rf_score_soft))\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_rf_score_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "similar-ceramic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: 0.8389\n",
      "Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: 0.8483\n"
     ]
    }
   ],
   "source": [
    "vc2.voting = 'soft'\n",
    "global_rf_score_soft = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "vc2.voting = 'hard'\n",
    "global_rf_score_hard = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_rf_score_soft))\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_rf_score_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "square-newsletter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parentesco_LE', 'rez_esc'}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useless_features = []\n",
    "drop_features = set()\n",
    "counter = 0\n",
    "for est in vc2.estimators_:\n",
    "    ranked_features, unused_features = feature_importance(est, X_train.drop(et_drop_cols, axis=1), display_results=False)\n",
    "    useless_features.append(unused_features)\n",
    "    if counter == 0:\n",
    "        drop_features = set(unused_features)\n",
    "    else:\n",
    "        drop_features = drop_features.intersection(set(unused_features))\n",
    "    counter += 1\n",
    "    \n",
    "drop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "polish-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_voters(data, weights=[0.5, 0.5]):\n",
    "    vc.voting=\"soft\"\n",
    "    vc1_probs = vc.predict_proba(data.drop(xgb_drop_cols, axis=1))\n",
    "    vc2.voting=\"soft\"\n",
    "    vc2_probs = vc2.predict_proba(data.drop(et_drop_cols, axis=1))\n",
    "    \n",
    "    final_vote = (vc1_probs * weights[0]) + (vc2_probs * weights[1])\n",
    "    predictions = np.argmax(final_vote, axis=1)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "forty-music",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8566882187579863"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_preds = combine_voters(X_test, weights=[0.5, 0.5])\n",
    "global_combo_score_soft = f1_score(y_test, combo_preds, average='macro')\n",
    "global_combo_score_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "future-bulletin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8520063251106894"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_preds = combine_voters(X_test, weights=[0.4, 0.6])\n",
    "global_combo_score_soft= f1_score(y_test, combo_preds, average='macro')\n",
    "global_combo_score_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "adolescent-volleyball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8576634664618535"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_preds = combine_voters(X_test, weights=[0.6, 0.4])\n",
    "global_combo_score_soft = f1_score(y_test, combo_preds, average='macro')\n",
    "global_combo_score_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-incidence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "unable-bradford",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "adverse-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix, f1_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "hispanic-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-longer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seorim",
   "language": "python",
   "name": "seorim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
